{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37a65b9-25a7-4b37-af0f-44d0c7036612",
   "metadata": {},
   "source": [
    "## Step 1: Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8f30c8-3aed-4935-bb76-17366a42bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab35520-8aa4-4602-873e-954e34466000",
   "metadata": {},
   "source": [
    "## Step 2: Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102b2dd6-f141-4b29-a1c8-309429e04d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931df75-c179-4505-b6ac-8997afba0bc2",
   "metadata": {},
   "source": [
    "## Step 3: Preprocessing Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3fdf68-5498-4ba7-b6d3-d8a07c030b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess customer data: one-hot encode the Region and calculate days since signup\n",
    "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
    "customers['SignupDuration'] = (pd.to_datetime('today') - customers['SignupDate']).dt.days\n",
    "\n",
    "# One-hot encode Region\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Updated to sparse_output=False\n",
    "region_encoded = encoder.fit_transform(customers[['Region']])\n",
    "region_df = pd.DataFrame(region_encoded, columns=encoder.categories_[0])\n",
    "\n",
    "# Combine customer data with region encoding\n",
    "customers_encoded = pd.concat([customers[['CustomerID', 'SignupDuration']], region_df], axis=1)\n",
    "\n",
    "# Preprocess product data: One-hot encode product categories\n",
    "product_encoder = OneHotEncoder(sparse_output=False)\n",
    "product_encoded = product_encoder.fit_transform(products[['Category']])\n",
    "product_df = pd.DataFrame(product_encoded, columns=product_encoder.categories_[0])\n",
    "\n",
    "# Now let's merge the transaction data with customer and product data\n",
    "# Join transaction with customer and product info\n",
    "transaction_data = transactions.merge(customers[['CustomerID', 'SignupDuration']], on='CustomerID', how='left')\n",
    "transaction_data = transaction_data.merge(products[['ProductID', 'Category']], on='ProductID', how='left')\n",
    "\n",
    "# One-hot encode the 'Category' column in transaction data\n",
    "transaction_data['Category'] = transaction_data['Category'].fillna('Unknown')  # Ensure no NaN values\n",
    "category_encoded = product_encoder.transform(transaction_data[['Category']])\n",
    "category_df = pd.DataFrame(category_encoded, columns=product_encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32dcdd-1eb0-4e79-9131-2b2d74374207",
   "metadata": {},
   "source": [
    "## Step 4: Preprocess Transaction Data\n",
    "Aggregating the transaction data to get transaction features like the total number of transactions, average transaction value, recency of the last purchase, and average quantity purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9678f477-b523-47d8-9b58-c1123be6a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge transactions with product information\n",
    "transactions = transactions.merge(products[['ProductID', 'Category']], on='ProductID', how='left')\n",
    "\n",
    "# Aggregate transaction features per customer\n",
    "transaction_agg = transactions.groupby('CustomerID').agg(\n",
    "    num_transactions=('TransactionID', 'count'),\n",
    "    avg_transaction_value=('TotalValue', 'mean'),\n",
    "    most_frequent_category=('Category', lambda x: x.mode()[0]),  # Most frequent product category\n",
    "    last_purchase_recency=('TransactionDate', lambda x: (pd.to_datetime('today') - pd.to_datetime(x.max())).days),\n",
    "    avg_quantity=('Quantity', 'mean')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bcdb4e-5c3f-4e7a-8a2d-feb5ddfd4080",
   "metadata": {},
   "source": [
    "## Step 5: Merging Customer and Transaction Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c25e296-5ba2-4367-8ecf-34ce63cfa2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([transaction_data[['SignupDuration']], category_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbbbdb-508d-4f01-9d0a-69bd36e714d0",
   "metadata": {},
   "source": [
    "## Step 6: Building Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46e4e33c-141a-4929-840d-2f4e60255a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 5)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'features' DataFrame already includes the 'CustomerID' column\n",
    "# and that all features are already encoded\n",
    "\n",
    "# Retain CustomerID in the features dataframe to use it for groupby\n",
    "features['CustomerID'] = transaction_data['CustomerID']\n",
    "\n",
    "# Now group by CustomerID and take the mean of features for each customer\n",
    "feature_matrix = features.groupby('CustomerID').mean()\n",
    "\n",
    "# Calculate cosine similarity between the customers\n",
    "similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "# Check if the feature_matrix is correct and shape is as expected\n",
    "print(feature_matrix.shape)\n",
    "\n",
    "# Now similarity_matrix will have the similarity scores between customers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a4521-c123-419b-b1e9-3897c6e0062f",
   "metadata": {},
   "source": [
    "## Step 7: Calculating Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c929cd2-94dc-41d6-b43e-35cc1e39498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99999963 0.99999881 ... 0.99999983 0.99999989 0.99999971]\n",
      " [0.99999963 1.         0.99999909 ... 0.99999978 0.99999968 0.99999986]\n",
      " [0.99999881 0.99999909 1.         ... 0.99999874 0.99999929 0.99999913]\n",
      " ...\n",
      " [0.99999983 0.99999978 0.99999874 ... 1.         0.99999967 0.99999986]\n",
      " [0.99999989 0.99999968 0.99999929 ... 0.99999967 1.         0.99999963]\n",
      " [0.99999971 0.99999986 0.99999913 ... 0.99999986 0.99999963 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between all customers\n",
    "assert similarity_matrix.shape[0] == similarity_matrix.shape[1]\n",
    "\n",
    "# Print similarity matrix for verification (optional)\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b245e52-74ca-471b-adfb-926df2c6b9d4",
   "metadata": {},
   "source": [
    "## Step 8: Generate Lookalike Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88f58071-9605-4b75-99d5-e9e9b45d8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dictionary to store recommendations\n",
    "lookalike_recommendations = {}\n",
    "\n",
    "for i, customer_id in enumerate(customer_features['CustomerID']):\n",
    "    # Get the similarity scores for this customer with all other customers\n",
    "    similarity_scores = similarity_matrix[i]\n",
    "    \n",
    "    # Create a list of (customer_id, similarity_score) pairs, excluding the customer itself\n",
    "    similar_customers = [\n",
    "        (customer_features['CustomerID'][j], similarity_scores[j]) \n",
    "        for j in range(len(similarity_scores)) if customer_features['CustomerID'][j] != customer_id\n",
    "    ]\n",
    "    \n",
    "    # Sort the similar customers by similarity score (descending) and get the top 3\n",
    "    similar_customers_sorted = sorted(similar_customers, key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    # Store the top 3 similar customers and their similarity scores\n",
    "    lookalike_recommendations[customer_id] = similar_customers_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34c978-beff-467d-8031-f35cdcd327d0",
   "metadata": {},
   "source": [
    "## Step 9: Prepare the Lookalike.csv Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2df7b9f1-2514-44a2-bd63-5ed25cb4c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the Lookalike.csv file\n",
    "lookalike_data = []\n",
    "for customer_id, recommendations in lookalike_recommendations.items():\n",
    "    for recommended_customer_id, score in recommendations:\n",
    "        lookalike_data.append([customer_id, recommended_customer_id, score])\n",
    "\n",
    "# Create DataFrame for lookalike recommendations\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'LookalikeCustomerID', 'SimilarityScore'])\n",
    "\n",
    "# Save the results to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43175b72-a975-4419-a12d-e316e81603cf",
   "metadata": {},
   "source": [
    "## Step 10: Jupyter Notebook Explanation\n",
    "\n",
    "\n",
    "### 1. Data Preprocessing:\n",
    "In this section, we focus on cleaning and transforming the raw data into a suitable format for analysis.\n",
    "\n",
    "One-Hot Encoding for Region:\n",
    "The Region column contains categorical values representing the continents where customers are located (e.g., 'Asia', 'Europe', etc.). Since machine learning algorithms cannot directly work with categorical data, we use one-hot encoding to transform this column into multiple binary columns (one for each continent). This helps represent each region as a numerical feature.\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "region_encoded = encoder.fit_transform(customers[['Region']])\n",
    "region_df = pd.DataFrame(region_encoded, columns=encoder.categories_[0])\n",
    "Calculating SignupDuration:\n",
    "To capture how long each customer has been signed up, we calculate the duration from their signup date to the current date. This is represented as the number of days since they signed up.\n",
    "\n",
    "customers['SignupDuration'] = (pd.to_datetime('today') - customers['SignupDate']).dt.days\n",
    "By applying these transformations, we ensure that the data is ready for feature engineering, which allows us to capture meaningful insights about the customers’ profiles.\n",
    "\n",
    "### 2. Feature Engineering:\n",
    "This section focuses on creating meaningful features from the transaction data, which can help identify similar customers.\n",
    "\n",
    "Aggregating Transaction Data: We aggregate transaction data at the customer level by calculating several key metrics:\n",
    "\n",
    "Number of Transactions: How many times the customer has made a purchase.\n",
    "Average Transaction Value: The mean value of each transaction, which helps to understand the customer's spending behavior.\n",
    "Most Frequent Product Category: The most commonly purchased category by the customer, indicating their primary area of interest.\n",
    "Recency of Last Purchase: The time difference in days from the customer’s last purchase to the current date. This helps in identifying active vs. dormant customers.\n",
    "Average Quantity Purchased: The average number of items bought in each transaction, which reflects how much the customer typically purchases per order.\n",
    "\n",
    "customer_transactions = transactions.groupby('CustomerID').agg(\n",
    "    num_transactions=('TransactionID', 'count'),\n",
    "    avg_transaction_value=('TotalValue', 'mean'),\n",
    "    most_frequent_category=('Category', lambda x: x.mode()[0]),\n",
    "    recency_of_last_purchase=('TransactionDate', lambda x: (pd.to_datetime('today') - pd.to_datetime(x.max())).days),\n",
    "    avg_quantity_purchased=('Quantity', 'mean')\n",
    ").reset_index()\n",
    "These aggregated metrics are essential for creating a comprehensive customer profile, which can be used to compare and recommend similar customers.\n",
    "\n",
    "### 3. Cosine Similarity:\n",
    "Cosine similarity measures the cosine of the angle between two vectors, which quantifies how similar the two vectors are. The cosine similarity ranges from -1 (completely dissimilar) to 1 (completely similar), with 0 indicating orthogonal vectors (no similarity).\n",
    "\n",
    "Feature Matrix Construction:\n",
    "Once the feature vectors for each customer are constructed (containing the aggregated transaction data and preprocessed customer information), we calculate the cosine similarity between these customer feature vectors.\n",
    "\n",
    "feature_matrix = pd.concat([customers.drop('CustomerID', axis=1), customer_transactions.drop('CustomerID', axis=1)], axis=1)\n",
    "similarity_matrix = cosine_similarity(feature_matrix)\n",
    " \n",
    "The result is a similarity matrix, where each element represents the similarity between two customers. This helps us understand how similar any two customers are based on their features.\n",
    "\n",
    "### 4. Recommendation Logic:\n",
    "In this step, we use the cosine similarity values to recommend the top 3 most similar customers for a given customer.\n",
    "\n",
    "Selecting Top 3 Similar Customers: For each customer (from CustomerID C0001 to C0020), we compute the top 3 customers with the highest similarity scores. This is done by sorting the similarity matrix for each customer and selecting the top 3 most similar customers.\n",
    "\n",
    "recommendations = {}\n",
    "\n",
    "for customer_id in range(1, 21):  # For C0001 to C0020\n",
    "    # Get the similarity scores for the current customer\n",
    "    customer_similarities = similarity_matrix[customer_id - 1]\n",
    "    \n",
    "    # Get the indices of the top 3 most similar customers\n",
    "    top_similar_customers = customer_similarities.argsort()[-4:-1][::-1]\n",
    "    \n",
    "    # Store the recommendations\n",
    "    recommendations[f'C{str(customer_id).zfill(4)}'] = [\n",
    "        (f'C{str(i+1).zfill(4)}', customer_similarities[i]) for i in top_similar_customers\n",
    "    ]\n",
    "Here, for each customer, the argsort() function is used to sort the similarity scores in descending order, and the top 3 customers are selected for recommendation.\n",
    "\n",
    "### 5. Output:\n",
    "The final output of the model is a CSV file that contains the recommended similar customers for each target customer (C0001 - C0020), along with their corresponding similarity scores.\n",
    "\n",
    "Saving to Lookalike.csv:\n",
    "The Lookalike.csv will have the format Map<CustomerID, List<RecommendedCustomerID, SimilarityScore>>. Each row corresponds to a target customer and their 3 most similar customers along with the similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cddb7-8d31-4ce8-b278-fc1e63e8f1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
